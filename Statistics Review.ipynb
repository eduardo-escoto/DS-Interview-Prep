{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics Review for Interviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability Axioms\n",
    "Introduced by Kolmogorov to formalize Probability Spaces. Cox's Theorem provides alternative formulations of probability that tend to be preferred by Bayesians.\n",
    "\n",
    "Let $(\\Omega, \\mathcal{F}, P)$ be a measure space. Where $P$ is the probability measure, $\\Omega$ is the sample space, $\\mathcal{F}$ is the event space. Then we have the following axioms:\n",
    "\n",
    "1. $P(E) \\in \\mathbb{R}, P(E) \\geq 0 \\quad \\forall E \\in \\mathcal{F}$\n",
    "    - Here we see that the probability is a non-negative real number for any set $E$ defined in the event space $\\mathcal{F}$.\n",
    "    - It follows that the probability measure is always finite from the next axiom in combination with this one.\n",
    "2. $P(\\Omega) = 1$\n",
    "    - This is the assumption of the unit measure. Intuitively, this axiom states that the probability of the sample space, $\\Omega$ is $1$.\n",
    "3. $P\\left(\\bigcup^{\\infty}_{i = 1} E_i\\right) = \\sum_{i = 1}^{\\infty} P(E_i), \\quad E_{k} \\cap E_{j} = \\emptyset, j \\neq k$\n",
    "    - This is the assumption of $\\sigma$-additivity in measures. \n",
    "    - In other words, the probability measure of the unions of disjoint events is the sum of probability measures of each event.\n",
    "    \n",
    "From these three axioms, the rest of probability can be derived as a consequence of the axioms and other properties from measure theory.\n",
    "\n",
    "**Note: Qausiprobabilities relax the third axiom of $\\sigma$-additivity**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful Consequences of the Probability Axioms\n",
    "\n",
    "#### Monotonicity\n",
    "Intuitively, an event $A$ is a subset of an event $B$, then the probability measure of $A$ should be less than $B$. So more formally we have:\n",
    "$$A \\subseteq B \\implies P(A) \\leq P(B)$$\n",
    "\n",
    "**Proof Idea: Show that $B$ can be composed of $A$ and some other sets from $B$ by using set excision.**\n",
    "\n",
    "#### Empty Set\n",
    "A null event should have probability of $0$. \"No event happening\" shouldn't be assigned a probability logically. Formally:\n",
    "$$P(\\emptyset) = 0$$\n",
    "Important to note, that for some event $E$, that $P(E) = 0 \\nRightarrow E = \\emptyset$. In other words, an event with probability zero does not mean that the event is the null set. To put it another way, the empty set is not the only set with probability measure $0$.\n",
    "\n",
    "**Proof Idea: Use a similar idea from the monotonicity prove, except by contradiction, where if $P(\\emptyset) \\neq 0$ then the sum of the sets goes to infinity, so its necessarily $0$.**\n",
    "\n",
    "#### The Complement\n",
    "The complement of an event, will yield $1$ minus the probability of that event. This can easily be seen since $A \\cup A^{c} = \\Omega  \\quad \\forall A \\in \\Omega$. So formally:\n",
    "$$\n",
    "P(A^{c}) = P(\\Omega \\setminus A) = 1 - P(A)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditional Probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discrete Probability Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continuous Probability Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditionally Independent Random Variables\n",
    "- $Y_1, \\dots Y_n$ are random variables. \n",
    "- We say they are conditionally independent given $\\theta$ if each $Y_i$ only gives information about $\\theta$ and not about any other $Y_j$. \n",
    "\n",
    "Formally, given events $A,B,C$, then $A$ and $B$ are conditionally independent given $C$ if $P(A \\cap B\\vert C) = P(A\\vert C)P(B\\vert C)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Likelihood:\n",
    "- The \"probability of the observed data\" expressed as a function of the parameter\n",
    "- Likelihood is NOT a distribution\n",
    "- Depends on the observed data\n",
    "- Asymptotically approaches the true value of the parameter\n",
    "- Unbiased estimator, may be less performant with smaller samples vs a biased estimator\n",
    "\n",
    "If the samples are conditionally independent, i.e. i.i.d or independent, then we can express probabilities as:\n",
    "$$P(y_1,\\dots, y_n \\vert \\theta) = P(y_1 \\cap \\dots \\cap y_n \\vert \\theta) = P(y_1 \\vert \\theta)\\cdot\\dots\\cdot P(y_n \\vert \\theta)$$\n",
    "\n",
    "Which then leads to the definition as:\n",
    "$$L(\\theta \\vert y_1, \\dots, y_n) = P(y_1, \\dots, y_n \\vert \\theta) = \\prod_{k=1}^{n} P(y_k \\vert \\theta)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximum Likelihood Estimation\n",
    "- We essentially estimate the parameter value $\\theta$ by maximizing the likelihood function $L(\\theta)$.\n",
    "- Often times we use calculus. I.E take partial derivatives and solve for where $L'(\\theta) = 0$\n",
    "- Often times more useful to use the log-likelihood, $\\ell(\\theta) = \\log \\left\\{L(\\theta)\\right\\}$ as this turns products into sums and makes solving easier.\n",
    "    - Note that the log is monotonic, and takes the maximum at the same value of $\\theta$ as the likelihood."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
